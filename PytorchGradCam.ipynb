{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJaqGe+EGJZTjZsr8rVgw7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frozenparadox99/Pytorch-Grad-CAM/blob/main/PytorchGradCam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s0Y9qk60NZ17"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "9h5en9Q-Ndpz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls \"/content/drive/My Drive/prep_data\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egX4TtLwOCoM",
        "outputId": "2cebe78f-f02e-4fa8-ecc4-a1e320adc7ea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "TEST_COVID  TRAIN_COVID\t\t   TRAIN_COVID_RESIZE  TRAIN_NON_AUGMENTED\n",
            "TEST_NON    TRAIN_COVID_AUGMENTED  TRAIN_NON\t       TRAIN_NON_RESIZE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path_covid = '/content/drive/My Drive/prep_data/TRAIN_COVID/'\n",
        "train_data_path_non_covid = '/content/drive/My Drive/prep_data/TRAIN_NON/'"
      ],
      "metadata": {
        "id": "xUOgManARBSC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dataset class\n",
        "class COVIDDataset(Dataset):\n",
        "    def __init__(self, data_path_label_1, data_path_label_2,transform=None):\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        \n",
        "\n",
        "        for filename in os.listdir(data_path_label_1):\n",
        "          if '.png' in filename:\n",
        "            final_path = data_path_label_1 + filename\n",
        "            self.data.append((final_path, 1))\n",
        "        \n",
        "        for filename in os.listdir(data_path_label_2):\n",
        "          if '.png' in filename:\n",
        "            final_path = data_path_label_2 + filename\n",
        "            self.data.append((final_path, 0))\n",
        "        \n",
        "       \n",
        "    def __getitem__(self, index):\n",
        "        img_path, label = self.data[index]\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "PqPGsCdoNfcF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class COVIDNet(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(COVIDNet, self).__init__()\n",
        "        self.model = models.resnet18(pretrained=True)\n",
        "        num_ftrs = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "0f41k9LmN1rc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GradCam(image, model, target_layer):\n",
        "    model.eval()\n",
        "    feature_map, output = model(image)\n",
        "    one_hot = torch.zeros((1, output.size()[-1]), dtype=torch.float32, device=device)\n",
        "    one_hot[0][torch.argmax(output)] = 1\n",
        "    one_hot.requires_grad_(True)\n",
        "    model.zero_grad()\n",
        "    one_hot.backward()\n",
        "    grads = torch.mean(model.get_activations_gradient()[target_layer], axis=(2, 3))\n",
        "    feature_map = model.get_activations()[target_layer]\n",
        "    feature_weights = torch.nn.functional.adaptive_avg_pool2d(grads, 1)\n",
        "    cam = torch.multiply(feature_map, feature_weights.unsqueeze(-1).unsqueeze(-1)).sum(1).unsqueeze(0)\n",
        "    cam = torch.nn.functional.relu(cam)\n",
        "    cam = cam - torch.min(cam)\n",
        "    cam = cam / torch.max(cam)\n",
        "    return cam"
      ],
      "metadata": {
        "id": "HPYhKl3IN4oS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "9UMgDsajN7BK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = COVIDDataset(train_data_path_covid, train_data_path_non_covid,transform=transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)"
      ],
      "metadata": {
        "id": "RVewMY2fRwfh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = COVIDNet(num_classes=2).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "CUkTqfF3OMj6"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i, (images, labels) in enumerate(train_dataloader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "ng7mExtAOMmR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in train_dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Calculate the accuracy and other metrics\n",
        "accuracy = 100 * correct / total\n",
        "confusion_matrix = np.zeros((2, 2), dtype=np.int64)\n",
        "for t, p in zip(y_true, y_pred):\n",
        "    confusion_matrix[t, p] += 1\n",
        "precision = confusion_matrix[1, 1] / np.sum(confusion_matrix[:, 1])\n",
        "recall = confusion_matrix[1, 1] / np.sum(confusion_matrix[1, :])\n",
        "f1_score = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "print('Accuracy:', accuracy)\n",
        "print('Confusion matrix:', confusion_matrix)\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('F1 score:', f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l03LwLlpOMod",
        "outputId": "c425eb5a-68af-42e0-ba48-f96568233261"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 97.89156626506023\n",
            "Confusion matrix: [[335  13]\n",
            " [  1 315]]\n",
            "Precision: 0.9603658536585366\n",
            "Recall: 0.9968354430379747\n",
            "F1 score: 0.9782608695652173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N38QRssCY4z5",
        "outputId": "90ce6305-d1a7-4a4c-d3d5-380e5d99ee81"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "COVIDNet(\n",
              "  (model): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Linear(in_features=512, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/content/drive/My Drive/prep_data/TRAIN_COVID/1.png'\n",
        "img = Image.open(image_path).convert('RGB')\n",
        "img_tensor = transform(img).unsqueeze(0)\n",
        "img_tensor.requires_grad_()\n",
        "output = model(img_tensor)\n",
        "_, pred = torch.max(output, 1)\n",
        "pred_class = pred.item()\n",
        "score = output[:, pred_class]\n",
        "model.zero_grad()\n",
        "score.backward()"
      ],
      "metadata": {
        "id": "FnxWTRJ_fRpv"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvpuUvJ0fkQT",
        "outputId": "e55fd93e-afe9-44c2-8efa-d50ddc41ec60"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.7410,  3.3886]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pwD_10ef2Wx",
        "outputId": "3bb01917-72ee-4da4-abf3-923e375df209"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c9pAJNvvhFkw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}